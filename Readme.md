# ğŸ¤– GenAI Data Analyst Agent

A production-ready **AI Data Analyst Agent** that allows users to upload datasets, ask natural-language business questions, automatically generate SQL, visualize results, and receive **LLM-powered executive insights** â€” all through a clean web interface.

ğŸ”— **Live App**: [https://genai-data-analyst-agent.onrender.com](https://genai-data-analyst-agent.onrender.com)
ğŸ”— **API Docs**: [https://genai-data-analyst-agent.onrender.com/docs](https://genai-data-analyst-agent.onrender.com/docs)

---

## ğŸš€ What This Project Does

This project simulates how a **real-world AI Data Analyst** works:

1. **Upload a dataset (CSV)**
2. **Ask questions in plain English** (e.g., *average daily rate by department*)
3. System automatically:

   * Converts the question into **SQL**
   * Executes it safely on the dataset
   * Generates **rule-based insights**
   * Creates **charts**
   * Produces a **consulting-style AI explanation** (executive summary, observations, recommendation)

This is not a demo toy â€” it is designed to be **resume-, interview-, and recruiter-ready**.

---

## ğŸ§  Key Features

* ğŸ” **Natural Language â†’ SQL** (LLM + rule-based fallback)
* ğŸ“Š **Automatic insights & KPIs**
* ğŸ“ˆ **Smart chart recommendations**
* ğŸ¤– **LLM-generated executive explanations** (structured, non-hallucinating)
* ğŸ§± **Fail-safe architecture** (fallbacks when LLMs fail or rate-limit)
* ğŸŒ **Deployed backend + frontend**

---

## ğŸ—ï¸ Architecture Overview

```
Frontend (Streamlit)
   â”‚
   â”‚ HTTP requests
   â–¼
Backend (FastAPI)
   â”œâ”€â”€ Dataset upload & schema detection
   â”œâ”€â”€ Query engine (NL â†’ SQL)
   â”œâ”€â”€ Rule-based insights engine
   â”œâ”€â”€ LLM services (SQL, charts, explanation)
   â””â”€â”€ SQLite execution layer
```

The system is intentionally **modular**, making it easy to extend with:

* MLflow
* Vector databases
* Authentication
* Caching

---

## ğŸ§° Tech Stack

**Frontend**

* Streamlit
* Plotly

**Backend**

* FastAPI
* SQLite
* Pandas

**GenAI / LLMs**

* Groq API
* LLaMA 3.1 (Instant)

**Deployment**

* Render (Web Service)

---

## ğŸ§Š Cold Start Notice (Important)

âš ï¸ **Cold Start Behavior (Render Free Tier)**

* The backend may **sleep after inactivity**
* First request can take **20â€“40 seconds** to respond

âœ… This is expected behavior on free-tier deployments.

**What to do if the app feels stuck:**

1. Open the API docs directly:
   ğŸ‘‰ [https://genai-data-analyst-agent.onrender.com/docs](https://genai-data-analyst-agent.onrender.com/docs)
2. Wait for the backend to wake up
3. Refresh the frontend page

Once warmed, the app works normally.

---

## ğŸ“¦ How to Run Locally

### 1ï¸âƒ£ Backend

```bash
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
uvicorn app.main:app --reload
```

Backend runs at:

```
http://localhost:8000
```

---

### 2ï¸âƒ£ Frontend

```bash
cd frontend
streamlit run app.py
```

Frontend runs at:

```
http://localhost:8501
```

Update this line in `frontend/app.py` when running locally:

```python
BACKEND_URL = "http://localhost:8000"
```

---

## ğŸ” Environment Variables

Create a `.env` file or set variables directly:

```bash
GROQ_API_KEY=your_api_key_here
```

---

## ğŸ“ Future Enhancements

* MLflow experiment tracking
* Dockerization
* CI/CD with GitHub Actions
* Authentication & user sessions
* Vector-based semantic querying

---

## ğŸ‘¤ Author

**Om Rohit Channoji**
AI / Data Science Enthusiast

---

â­ If you found this project useful, consider starring the repository!
